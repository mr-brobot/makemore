{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/names.txt') as nfile:\n",
    "    words = nfile.read().splitlines()\n",
    "\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import ascii_lowercase\n",
    "\n",
    "BOUNDARY = \".\"\n",
    "\n",
    "alphabet = [BOUNDARY] + list(ascii_lowercase)\n",
    "\n",
    "ctoi = {c: i for i, c in enumerate(alphabet)}\n",
    "\n",
    "ctoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Sample Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... -> e\n",
      "..e -> m\n",
      ".em -> m\n",
      "emm -> a\n",
      "mma -> .\n",
      "olivia\n",
      "... -> o\n",
      "..o -> l\n",
      ".ol -> i\n",
      "oli -> v\n",
      "liv -> i\n",
      "ivi -> a\n",
      "via -> .\n",
      "ava\n",
      "... -> a\n",
      "..a -> v\n",
      ".av -> a\n",
      "ava -> .\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# context length: how many previous characters are considered when predicting the next\n",
    "# n is used since, in bengio et al. 2003, this relates to ngram size\n",
    "n = 3\n",
    "\n",
    "# training set\n",
    "X, Y = [], []\n",
    "\n",
    "for word in words[:3]:\n",
    "    print(word)\n",
    "    context = [0] * n # when n = 3, results in [0, 0, 0]\n",
    "    for c in word + BOUNDARY:\n",
    "        i = ctoi[c]\n",
    "        X.append(context) # add context\n",
    "        Y.append(i) # add result\n",
    "\n",
    "        print(\"\".join(alphabet[j] for j in context), \"->\", c)\n",
    "\n",
    "        # update context (crop & append)\n",
    "        context = context[1:] + [i]\n",
    "\n",
    "X = torch.tensor(X).short()\n",
    "Y = torch.tensor(Y).short()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3]), torch.int16, torch.Size([16]), torch.int16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1]], dtype=torch.int16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0],\n",
       "       dtype=torch.int16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Bengio et al.](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf), embeddings are referred to as the feature vectors. The feature vectors \"embed\" the word/character into an `m`-dimensional space, where `m` is the number of features. The feature vectors are learned from the training set, alowing for words/characters to cluster together according to similarities relevant to the loss function. Because embedding features are learned, the network is free to use each feature in any way it sees fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 2 # in bengio et al. 2003, this is 30\n",
    "C = torch.randn(len(alphabet), features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2566, 2.4348])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# naive lookup\n",
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2566, 2.4348])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# vectorized lookup - similar to applying bit mask\n",
    "xenc = F.one_hot(torch.tensor(5), num_classes=len(alphabet)).short()\n",
    "xenc.float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2566, 2.4348],\n",
       "        [0.0904, 0.7293],\n",
       "        [1.0082, 0.4794],\n",
       "        [1.0082, 0.4794]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# possible to index using list or tensor\n",
    "C[torch.tensor([5, 6, 7, 7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27, 2]), torch.Size([16, 3]), torch.Size([16, 3, 2]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape, X.shape, C[X.long()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`C[X]` adds embeddings to the input data. The embeddings are learned during training. The embeddings are added to the input data as additional columns. The number of columns added is the number of embeddings specified. The embeddings are initialized to random values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context for each character in input\n",
    "emb = C[X.long()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each neuron will accept features for each character in context\n",
    "layer_inputs = n * features\n",
    "\n",
    "# layer size (total neurons) is arbitrary\n",
    "layer_size = 100\n",
    "\n",
    "W1 = torch.randn(layer_inputs, layer_size)\n",
    "b1 = torch.randn(layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 2]), torch.Size([6, 100]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape, W1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, we want to do something like `emb @ W1 + b1`. However, the matrix shapes are not compatible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 2]), torch.Size([16, 2]), torch.Size([16, 2]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[:, 0, :].shape, emb[:, 1, :].shape, emb[:, 2, :].shape,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see one method to extract the embeddings for each input. To pass to the hidden layer, we need to flatten the embeddings. We can do this by concatenating the embeddings for each input into a single vector for each input.\n",
    "\n",
    "Using `torch.view` to interpret the 1st and 2nd dimensions as a single dimension, we flatten the embeddings for each input into a single vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(-1, layer_inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 100])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = emb.view(-1, layer_inputs) @ W1 + b1\n",
    "\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn(layer_size, len(alphabet))\n",
    "b2 = torch.randn(len(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 27])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = h @ W2 + b2\n",
    "\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 27])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = logits.exp()\n",
    "\n",
    "prob = counts / counts.sum(dim=1, keepdim=True)\n",
    "\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0],\n",
       "       dtype=torch.int16)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1321e-10, 2.9531e-24, 1.6483e-21, 1.5406e-28, 1.2106e-24, 1.3649e-01,\n",
       "        1.8415e-26, 6.8954e-26, 1.0000e+00, 1.4099e-25, 2.2900e-28, 1.1657e-24,\n",
       "        1.9179e-18, 1.3328e-14, 1.4013e-45, 2.8128e-08])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek predictions for each label in the training set (after training, should approach 1)\n",
    "prob[torch.arange(16), Y.long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.7488)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(16), Y.long()].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3]), torch.Size([16]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=3 | features=2\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "features = 2\n",
    "\n",
    "print(f\"{n=} | {features=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn(len(alphabet), features, generator=g)\n",
    "W1 = torch.randn(n * features, 100, generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn(100, len(alphabet), generator=g)\n",
    "b2 = torch.randn(len(alphabet), generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_params=3481\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.nelement() for p in parameters)\n",
    "\n",
    "print(f\"{total_params=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.2417)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X.long()]\n",
    "h = torch.tanh(emb.view(-1, n * features) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(dim=1, keepdim=True)\n",
    "loss = -prob[torch.arange(16), Y.long()].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.2417)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(logits, Y.long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `cross_entropy` is equivalent to softmax + negative log likelihood, we will use `cross_entropy` going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2078, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    # forward pass\n",
    "    emb = C[X.long()]\n",
    "    h = torch.tanh(emb.view(-1, n * features) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y.long())\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    for p in parameters:\n",
    "        p.data -= 0.1 * p.grad\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "for word in words:\n",
    "    context = [0] * n # when n = 3, results in [0, 0, 0]\n",
    "    for c in word + BOUNDARY:\n",
    "        i = ctoi[c]\n",
    "        X.append(context) # add context\n",
    "        Y.append(i) # add result\n",
    "\n",
    "        # update context (crop & append)\n",
    "        context = context[1:] + [i]\n",
    "\n",
    "X = torch.tensor(X).short()\n",
    "Y = torch.tensor(Y).short()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.int16, torch.Size([228146]), torch.int16)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([172865, 114526,  56012, 110553, 171862, 164318,  21101,   9256,  85273,\n",
       "         34367, 188306,  44975,  53569, 147967,  25913,  10629, 115341, 222165,\n",
       "        164544,  66092,  81100, 151601,  87474, 167385,  66276, 141372, 196245,\n",
       "        204040, 222291, 118785,  60008, 225419])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch_size = 32\n",
    "\n",
    "torch.randint(0, X.shape[0], (minibatch_size, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6106, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3m 46s w/o minibatching\n",
    "# 1.3s w/ minibatching\n",
    "\n",
    "for _ in range(1000):\n",
    "    ix = torch.randint(0, X.shape[0], (minibatch_size, ))\n",
    "    # forward pass\n",
    "    emb = C[X.long()[ix]]\n",
    "    h = torch.tanh(emb.view(-1, n * features) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y.long()[ix])\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    for p in parameters:\n",
    "        p.data -= 0.1 * p.grad\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5414, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X.long()]\n",
    "h = torch.tanh(emb.view(-1, n * features) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Y.long())\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
